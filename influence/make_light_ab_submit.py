import pandas as pd

# ===============================
# ÏÑ§Ï†ï
# ===============================
TRAIN_PATH = "train_ratings.csv"
EASE_PATH = "ease.csv"
BERT_PATH = "bert.csv"

OUT_ALL_EASE = "submit_all_ease.csv"
OUT_LIGHT_BERT = "submit_light_bert_heavy_ease.csv"

LIGHT_THRESHOLD = 100  # light user Í∏∞Ï§Ä

# ===============================
# 1. train Îç∞Ïù¥ÌÑ∞Î°ú user interaction Ïàò Í≥ÑÏÇ∞
# ===============================
print("‚ñ∂ Loading train_ratings.csv")
train = pd.read_csv(TRAIN_PATH)

user_cnt = (
    train.groupby("user")
    .size()
    .reset_index(name="cnt")
)

light_users = set(user_cnt[user_cnt["cnt"] <= LIGHT_THRESHOLD]["user"])

print(f"Light users : {len(light_users)}")
print(f"Total users : {user_cnt.shape[0]}")

# ===============================
# 2. Ï∂îÏ≤ú Í≤∞Í≥º Î°úÎìú
# ===============================
print("‚ñ∂ Loading EASE / BERT predictions")
ease = pd.read_csv(EASE_PATH)
bert = pd.read_csv(BERT_PATH)

# sanity check
assert set(ease["user"]) == set(bert["user"]), "‚ùå EASE/BERT user mismatch"
assert ease.groupby("user").size().nunique() == 1, "‚ùå EASE not 10 items per user"
assert bert.groupby("user").size().nunique() == 1, "‚ùå BERT not 10 items per user"

# ===============================
# 3. Ï†úÏ∂ú A: All-EASE (baseline)
# ===============================
ease.to_csv(OUT_ALL_EASE, index=False)
print(f"‚úÖ Saved: {OUT_ALL_EASE}")

# ===============================
# 4. Ï†úÏ∂ú B: Light-BERT + Heavy-EASE
# ===============================
rows = []

for user, g in ease.groupby("user"):
    if user in light_users:
        # light user ‚Üí BERT
        rows.append(
            bert[bert["user"] == user]
        )
    else:
        # heavy user ‚Üí EASE Í∑∏ÎåÄÎ°ú
        rows.append(g)

submit_light_bert = (
    pd.concat(rows)
    .sort_values("user")
    .reset_index(drop=True)
)

submit_light_bert.to_csv(OUT_LIGHT_BERT, index=False)
print(f"‚úÖ Saved: {OUT_LIGHT_BERT}")

print("üéâ Done")
