# BERT4Rec Hyperparameter Tuning Guide

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#1-ê°œìš”)
2. [ì‚¬ì „ ì¤€ë¹„ ë° í™˜ê²½ ê²€ì¦](#2-ì‚¬ì „-ì¤€ë¹„-ë°-í™˜ê²½-ê²€ì¦)
3. [Tuning ë‹¨ê³„ë³„ í”„ë¡œì„¸ìŠ¤](#3-tuning-ë‹¨ê³„ë³„-í”„ë¡œì„¸ìŠ¤)
   - [Stage 0: Test Mode - í™˜ê²½ ê²€ì¦](#stage-0-test-mode---í™˜ê²½-ê²€ì¦)
   - [Stage 1: Quick Mode - ë¹ ë¥¸ íƒìƒ‰](#stage-1-quick-mode---ë¹ ë¥¸-íƒìƒ‰)
   - [Stage 2: Medium Mode - ì •ë°€ íƒìƒ‰](#stage-2-medium-mode---ì •ë°€-íƒìƒ‰)
   - [Stage 3: Seed Search - ì¬í˜„ì„± í™•ë³´](#stage-3-seed-search---ì¬í˜„ì„±-í™•ë³´)
4. [ì¼ë°˜í™”ë¥¼ ìœ„í•œ ì „ëµ](#4-ì¼ë°˜í™”ë¥¼-ìœ„í•œ-ì „ëµ)
5. [Tuning vs Training í™˜ê²½ ì¼ì¹˜](#5-tuning-vs-training-í™˜ê²½-ì¼ì¹˜)
6. [íŒŒë¼ë¯¸í„°ë³„ ê°€ì´ë“œ](#6-íŒŒë¼ë¯¸í„°ë³„-ê°€ì´ë“œ)
7. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#7-íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)
8. [Best Practices](#8-best-practices)

---

## 1. ê°œìš”

### 1.1 Tuningì˜ ëª©ì 

- âœ… **ì¼ë°˜í™” ì„±ëŠ¥ ìµœì í™”**: Validationë¿ ì•„ë‹ˆë¼ Public/Private test ì„±ëŠ¥ í–¥ìƒ
- âœ… **ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼**: Seed ê³ ì •ìœ¼ë¡œ deterministicí•œ ê²°ê³¼
- âœ… **íš¨ìœ¨ì ì¸ íƒìƒ‰**: ë‹¨ê³„ì  íƒìƒ‰ìœ¼ë¡œ ì‹œê°„/ë¹„ìš© ì ˆì•½
- âœ… **Overfitting ë°©ì§€**: Regularization íŒŒë¼ë¯¸í„° ìµœì í™”

### 1.2 í•µì‹¬ ì›ì¹™

```
ğŸ¯ ì›ì¹™ 1: Tuning í™˜ê²½ = Training í™˜ê²½
   - Scheduler, Dataset split, Loss function ë™ì¼
   - ë‹¤ë¥´ë©´ Tuning ê²°ê³¼ê°€ Trainingì— ì ìš© ì•ˆë¨

ğŸ¯ ì›ì¹™ 2: ì¼ë°˜í™” ìš°ì„ 
   - Val NDCG@10 ìµœê³  â‰  Public score ìµœê³ 
   - Regularization íŒŒë¼ë¯¸í„° ì¶©ë¶„íˆ í¬ê²Œ

ğŸ¯ ì›ì¹™ 3: ë‹¨ê³„ì  íƒìƒ‰
   - Test â†’ Quick â†’ Medium â†’ Seed
   - ë„“ê²Œ íƒìƒ‰ â†’ ì¢ê²Œ ì •ë°€í™”

ğŸ¯ ì›ì¹™ 4: ì¬í˜„ì„± í™•ë³´
   - Seed ê³ ì • í•„ìˆ˜
   - ëª¨ë“  ì‹¤í—˜ ê¸°ë¡
```

---

## 2. ì‚¬ì „ ì¤€ë¹„ ë° í™˜ê²½ ê²€ì¦

### 2.1 íŒŒì¼ êµ¬ì¡° í™•ì¸

```bash
lightning/
â”œâ”€â”€ tune/
â”‚   â”œâ”€â”€ tune_bert4rec_optuna.py          # Main tuning script
â”‚   â”œâ”€â”€ tune_bert4rec_optuna_monitored.py # ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
â”‚   â”œâ”€â”€ quick_tune.py                     # Quick mode helper
â”‚   â””â”€â”€ results/                          # Tuning ê²°ê³¼ ì €ì¥
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/bert4rec.py               # Model definition
â”‚   â””â”€â”€ data/bert4rec_data.py            # DataModule
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ bert4rec_v2.yaml                 # Training config
â””â”€â”€ train_bert4rec.py                    # Training script
```

### 2.2 í•„ìˆ˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

```bash
# 1. ë°ì´í„° í™•ì¸
ls -lh ~/data/train/train_ratings.csv

# 2. í™˜ê²½ í™•ì¸
source .venv/bin/activate
python -c "import torch, lightning, optuna; print('OK')"

# 3. GPU í™•ì¸
nvidia-smi

# 4. ì´ì „ DB ë°±ì—…
cd ~/juik/lightning/tune
ls -lh *.db
cp important.db important_backup_$(date +%Y%m%d).db
```

---

## 3. Tuning ë‹¨ê³„ë³„ í”„ë¡œì„¸ìŠ¤

## Stage 0: Test Mode - í™˜ê²½ ê²€ì¦

**ëª©ì **: ì „ì²´ íŒŒì´í”„ë¼ì¸ì´ ì •ìƒ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸

### Step 0-1: ë‹¨ì¼ Trial í…ŒìŠ¤íŠ¸

```bash
cd ~/juik/lightning/tune

# quick_tune.pyë¥¼ test ëª¨ë“œë¡œ ì‹¤í–‰
python quick_tune.py --mode test
```

**ë˜ëŠ” ì§ì ‘ ì‹¤í–‰**:
```bash
python tune_bert4rec_optuna.py \
    --study_name bert4rec_test \
    --n_trials 2 \
    --n_epochs 2
```

**í™•ì¸ ì‚¬í•­**:
- âœ… ì—ëŸ¬ ì—†ì´ ì™„ë£Œ
- âœ… DB íŒŒì¼ ìƒì„± (`bert4rec_test.db`)
- âœ… NDCG@10 ê°’ ì¶œë ¥ (ì •ìƒ ë²”ìœ„: 0.01~0.05)
- âœ… ì‹¤í–‰ ì‹œê°„ (3 epochs: ~5-10ë¶„)

### Step 0-2: Tuning vs Training í™˜ê²½ ì¼ì¹˜ ê²€ì¦

**ì¤‘ìš”**: Tuningì—ì„œ ì°¾ì€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ê°€ Trainingì—ì„œ ì¬í˜„ë˜ë ¤ë©´ í™˜ê²½ì´ ë™ì¼í•´ì•¼ í•¨

#### âœ… Checkpoint 1: Seed ì„¤ì •

```python
# tune_bert4rec_optuna.py (Line 62-63)
import lightning as L
L.seed_everything(42, workers=True)

# train_bert4rec.py (Line 40)
L.seed_everything(cfg.data.seed, workers=True)

# bert4rec_v2.yaml (Line 17)
data:
  seed: 42
```

**ê²€ì¦**:
```bash
grep "seed_everything" tune/tune_bert4rec_optuna.py
grep "seed_everything" train_bert4rec.py
grep "seed:" configs/bert4rec_v2.yaml
```

#### âœ… Checkpoint 2: LR Scheduler ì¼ì¹˜

**ëª©ì **: Tuning í™˜ê²½ê³¼ Training í™˜ê²½ì˜ LR schedulerê°€ ë™ì¼í•œì§€ í™•ì¸

**Tuning í™˜ê²½**:
```python
# tune_bert4rec_optuna.py â†’ BERT4Rec ëª¨ë¸ ì‚¬ìš©
# src/models/bert4rec.pyì˜ configure_optimizers() í˜¸ì¶œ
```

**Training í™˜ê²½**:
```python
# train_bert4rec.py â†’ ë™ì¼í•œ BERT4Rec ëª¨ë¸ ì‚¬ìš©
# src/models/bert4rec.pyì˜ configure_optimizers() í˜¸ì¶œ
```

**í™•ì¸ ë°©ë²•**:
```python
# src/models/bert4rec.py (Line 641-658)
def configure_optimizers(self):
    optimizer = torch.optim.AdamW(...)

    # Case 1: Scheduler ì—†ìŒ
    return optimizer
    # â†’ Tuningê³¼ Training ëª¨ë‘ constant LR

    # Case 2: Scheduler ìˆìŒ
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(...)
    return [optimizer], [scheduler]
    # â†’ Tuningê³¼ Training ëª¨ë‘ cosine scheduler ì‚¬ìš©
```

**ê²€ì¦**:
```bash
# Scheduler ì„¤ì • í™•ì¸
grep -A 15 "def configure_optimizers" src/models/bert4rec.py

# Tuningê³¼ Trainingì´ ê°™ì€ BERT4Rec í´ë˜ìŠ¤ ì‚¬ìš©í•˜ëŠ”ì§€ í™•ì¸
grep "from src.models.bert4rec import BERT4Rec" tune/tune_bert4rec_optuna.py
grep "from src.models.bert4rec import BERT4Rec" train_bert4rec.py
```

**ì¤‘ìš”**:
- Schedulerë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ Tuningì—ì„œë„ ì‚¬ìš©í•´ì•¼ í•¨
- Schedulerë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë ¤ë©´ ë‘˜ ë‹¤ ì‚¬ìš©í•˜ì§€ ì•Šì•„ì•¼ í•¨
- **í˜„ì¬ ê¶Œì¥**: Scheduler ì—†ìŒ (constant LR)ì´ BERT4Recì— ë” ì í•©

#### âœ… Checkpoint 3: Dataset Split

```python
# src/data/bert4rec_data.py (Line 596-604)
for user, seq in user_sequences.items():
    if self.use_full_data:
        self.user_train[user] = seq
        self.user_valid[user] = seq[-1]  # Dummy
    else:
        self.user_train[user] = seq[:-1]  # âœ“ Last item split
        self.user_valid[user] = seq[-1]
```

**Tuningê³¼ Training ëª¨ë‘**:
```python
use_full_data=False  # âœ“ ë™ì¼
```

**ê²€ì¦**:
```bash
grep "use_full_data" tune/tune_bert4rec_optuna.py
grep "use_full_data" configs/bert4rec_v2.yaml
```

#### âœ… Checkpoint 4: Loss Function & Metrics

```python
# src/models/bert4rec.py
# Training step (Line 460-490)
loss = F.cross_entropy(logits, labels)

# Validation step (Line 527-639)
# NDCG@10 ê³„ì‚° ë¡œì§ ë™ì¼
val_ndcg_10 = ndcg_values.sum().item() / batch_size
```

**í™•ì¸**: ë™ì¼í•œ `BERT4Rec` í´ë˜ìŠ¤ ì‚¬ìš©
```bash
grep "from src.models.bert4rec import BERT4Rec" tune/tune_bert4rec_optuna.py
grep "from src.models.bert4rec import BERT4Rec" train_bert4rec.py
```

#### âœ… Checkpoint 5: Default ê°’ ì¼ì¹˜ í™•ì¸

**ëª©ì **: Tuningê³¼ Trainingì—ì„œ **ëª…ì‹œí•˜ì§€ ì•Šì€ íŒŒë¼ë¯¸í„°**ì˜ ê¸°ë³¸ê°’ì´ ë™ì¼í•œì§€ í™•ì¸

**í™•ì¸ì´ í•„ìš”í•œ ì´ìœ **:
- Tuningì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •í•˜ì§€ ì•Šì€ íŒŒë¼ë¯¸í„°ê°€ ìˆì„ ìˆ˜ ìˆìŒ
- Training configì—ë§Œ ìˆëŠ” ì„¤ì •ì´ ê²°ê³¼ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŒ
- ë‘ í™˜ê²½ì˜ ì•”ë¬µì  ê¸°ë³¸ê°’ì´ ë‹¤ë¥´ë©´ ì¬í˜„ ë¶ˆê°€

**ì£¼ìš” ì²´í¬ í•­ëª©**:

```python
# 1. Metadata ì‚¬ìš© ì—¬ë¶€
# tune_bert4rec_optuna.py (Line 95-99)
datamodule = BERT4RecDataModule(
    ...
    use_genre_emb=False,      # âœ“ ëª…ì‹œì ìœ¼ë¡œ False
    use_director_emb=False,   # âœ“ ëª…ì‹œì ìœ¼ë¡œ False
    use_writer_emb=False,     # âœ“ ëª…ì‹œì ìœ¼ë¡œ False
    use_title_emb=False,      # âœ“ ëª…ì‹œì ìœ¼ë¡œ False
)

# bert4rec_v2.yaml (Line 38-41)
model:
  use_genre_emb: false        # âœ“ ì¼ì¹˜
  use_director_emb: false     # âœ“ ì¼ì¹˜
  use_writer_emb: false       # âœ“ ì¼ì¹˜
  use_title_emb: false        # âœ“ ì¼ì¹˜
```

```python
# 2. Data ê´€ë ¨ ì„¤ì •
# tune_bert4rec_optuna.py
datamodule = BERT4RecDataModule(
    min_interactions=3,       # âœ“ ëª…ì‹œ
    seed=42,                  # âœ“ ëª…ì‹œ
    num_workers=4,            # âœ“ ëª…ì‹œ
    use_full_data=False,      # âœ“ ëª…ì‹œ
)

# bert4rec_v2.yaml
data:
  min_interactions: 3         # âœ“ ì¼ì¹˜
  seed: 42                    # âœ“ ì¼ì¹˜ (ë˜ëŠ” 7222)
  num_workers: 4              # âœ“ ì¼ì¹˜
  use_full_data: false        # âœ“ ì¼ì¹˜
```

```python
# 3. Training ì„¤ì •
# tune_bert4rec_optuna.py (Line 149-160)
trainer = L.Trainer(
    precision="16-mixed",     # âœ“ ëª…ì‹œ
    gradient_clip_val=5.0,    # âœ“ ëª…ì‹œ
    ...
)

# bert4rec_v2.yaml (Line 57-59)
training:
  precision: "16-mixed"       # âœ“ ì¼ì¹˜
  gradient_clip_val: 5.0      # âœ“ ì¼ì¹˜
```

```python
# 4. Model ê¸°ë³¸ ì„¤ì •
# tune_bert4rec_optuna.py (Line 120)
model = BERT4Rec(
    share_embeddings=True,    # âœ“ ëª…ì‹œ
    ...
)

# bert4rec_v2.yaml (Line 35)
model:
  share_embeddings: true      # âœ“ ì¼ì¹˜
```

**ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸**:
```python
# verify_defaults.py
import yaml

# Tuning ê¸°ë³¸ê°’ (ì½”ë“œì—ì„œ ì¶”ì¶œ)
tuning_defaults = {
    "use_genre_emb": False,
    "use_director_emb": False,
    "use_writer_emb": False,
    "use_title_emb": False,
    "min_interactions": 3,
    "num_workers": 4,
    "use_full_data": False,
    "precision": "16-mixed",
    "gradient_clip_val": 5.0,
    "share_embeddings": True,
}

# Training config ë¡œë“œ
with open("../configs/bert4rec_v2.yaml") as f:
    training_config = yaml.safe_load(f)

# ë¹„êµ
print("Default Values Verification")
print("=" * 80)

mismatches = []
for key, tuning_val in tuning_defaults.items():
    # Configì—ì„œ ê°’ ì°¾ê¸°
    if key.startswith("use_"):
        training_val = training_config["model"].get(key)
    elif key in ["min_interactions", "num_workers", "use_full_data"]:
        training_val = training_config["data"].get(key)
    elif key in ["precision", "gradient_clip_val"]:
        training_val = training_config["training"].get(key)
    else:
        training_val = training_config["model"].get(key)

    match = tuning_val == training_val
    status = "âœ“" if match else "âœ—"

    print(f"{status} {key:25s}: Tuning={tuning_val:10s}, Training={training_val}")

    if not match:
        mismatches.append((key, tuning_val, training_val))

if mismatches:
    print("\nâš ï¸ Mismatches found:")
    for key, tuning_val, training_val in mismatches:
        print(f"  {key}: {tuning_val} (Tuning) â‰  {training_val} (Training)")
    print("\nAction required: Update Tuning or Training config to match")
else:
    print("\nâœ“ All default values match!")
```

```bash
cd ~/juik/lightning/tune
python verify_defaults.py
```

**ì¼ë°˜ì ì¸ ë¶ˆì¼ì¹˜ ì˜ˆì‹œì™€ í•´ê²°**:

```python
# ë¬¸ì œ: Tuningì—ì„œ metadata ë¯¸ì§€ì • â†’ ê¸°ë³¸ê°’ ì‚¬ìš©
# tune_bert4rec_optuna.py (ì˜ëª»ëœ ì˜ˆ)
datamodule = BERT4RecDataModule(...)
# use_genre_emb ë¯¸ì§€ì • â†’ DataModuleì˜ ê¸°ë³¸ê°’ ì‚¬ìš© (Trueì¼ ìˆ˜ë„!)

# í•´ê²°: ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
datamodule = BERT4RecDataModule(
    use_genre_emb=False,  # âœ“ ëª…ì‹œ
    ...
)
```

**ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] Metadata ì‚¬ìš© ì—¬ë¶€ (use_*_emb) ì¼ì¹˜
- [ ] Data ì„¤ì • (min_interactions, seed, num_workers, use_full_data) ì¼ì¹˜
- [ ] Training ì„¤ì • (precision, gradient_clip_val) ì¼ì¹˜
- [ ] Model ì„¤ì • (share_embeddings) ì¼ì¹˜
- [ ] ëª¨ë“  ì•”ë¬µì  ê¸°ë³¸ê°’ í™•ì¸

### Step 0-3: í™˜ê²½ ì¼ì¹˜ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

```python
# verify_env.py
import sys
sys.path.append('.')

print("=" * 80)
print("Tuning vs Training Environment Verification")
print("=" * 80)

# 1. Seed
print("\n1. Seed Configuration:")
print("   Tuning: L.seed_everything(42, workers=True)")
print("   Training: L.seed_everything(cfg.data.seed, workers=True)")
print("   Config: seed=42")
print("   âœ“ Consistent")

# 2. Scheduler
from src.models.bert4rec import BERT4Rec
import torch

model = BERT4Rec(num_items=1000, hidden_units=64, max_len=50, lr=0.001)
optimizer_config = model.configure_optimizers()

print("\n2. LR Scheduler:")
if isinstance(optimizer_config, list):
    print("   âœ— Scheduler detected!")
    print("   Tuning and Training will have different LR schedules")
else:
    print("   âœ“ No scheduler (matches Tuning)")

# 3. Dataset split
from src.data.bert4rec_data import BERT4RecDataModule
dm = BERT4RecDataModule(
    data_dir="~/data/train/",
    data_file="train_ratings.csv",
    use_full_data=False
)
print("\n3. Dataset Split:")
print(f"   use_full_data: False")
print("   âœ“ Last-item split (matches Tuning)")

# 4. Metrics
print("\n4. Loss & Metrics:")
print("   Loss: CrossEntropy (same BERT4Rec class)")
print("   Metric: NDCG@10 (same validation_step)")
print("   âœ“ Identical")

print("\n" + "=" * 80)
print("Environment Verification: PASSED")
print("=" * 80)
```

```bash
python verify_env.py
```

---

## Stage 1: Quick Mode - ë¹ ë¥¸ íƒìƒ‰

**ëª©ì **:
- ë„“ì€ search spaceì—ì„œ promisingí•œ ì˜ì—­ ë¹ ë¥´ê²Œ íŒŒì•…
- **ì¼ë°˜í™”ë¥¼ ìœ„í•œ ìµœì†Œ regularization ê°’ í™•ì¸**
- 10-20 trials, 20-30 epochsë¡œ ë¹ ë¥¸ í”¼ë“œë°±

### Step 1-1: Quick Tuning ì‹¤í–‰

**quick_tune.py ì‚¬ìš© (ê¶Œì¥)**:
```bash
cd ~/juik/lightning/tune

# Quick mode ì‹¤í–‰ (100 trials, 20 epochs)
python quick_tune.py --mode quick
```

**ë˜ëŠ” ì§ì ‘ ì‹¤í–‰**:
```bash
python tune_bert4rec_optuna.py \
    --study_name bert4rec_quick \
    --n_trials 100 \
    --n_epochs 20 \
    --n_jobs 1
```

### Step 1-2: Quick ê²°ê³¼ ë¶„ì„

```python
# analyze_quick_results.py
import optuna
import numpy as np
from tabulate import tabulate

study = optuna.load_study(
    study_name="bert4rec_quick",
    storage="sqlite:///bert4rec_quick.db"
)

completed = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]

# íŒŒë¼ë¯¸í„°ë³„ ì¤‘ìš”ë„ ë¶„ì„
print("=" * 80)
print("Parameter Importance Analysis")
print("=" * 80)

param_importance = optuna.importance.get_param_importances(study)
for param, importance in sorted(param_importance.items(), key=lambda x: x[1], reverse=True):
    print(f"{param:25s}: {importance:.4f}")

# Top 5 trials ë¶„ì„
print("\n" + "=" * 80)
print("Top 5 Trials")
print("=" * 80)

top_trials = sorted(completed, key=lambda t: t.value, reverse=True)[:5]
for i, trial in enumerate(top_trials, 1):
    print(f"\n{i}. Trial #{trial.number}: NDCG@10 = {trial.value:.4f}")
    for key, value in trial.params.items():
        print(f"   {key:20s}: {value}")

# Regularization íŒŒë¼ë¯¸í„° ë¶„ì„ (ì¼ë°˜í™” ì¤‘ìš”!)
print("\n" + "=" * 80)
print("Regularization Parameters Analysis")
print("=" * 80)

reg_params = ['dropout_rate', 'weight_decay', 'random_mask_prob']
for param in reg_params:
    values = [t.params[param] for t in completed if param in t.params]
    scores = [t.value for t in completed if param in t.params]

    # ìƒìœ„ 20% trialsì˜ í‰ê· ê°’
    top_20_idx = np.argsort(scores)[-len(scores)//5:]
    top_20_values = [values[i] for i in top_20_idx]

    print(f"\n{param}:")
    print(f"  Overall range: [{min(values):.4f}, {max(values):.4f}]")
    print(f"  Top 20% avg:   {np.mean(top_20_values):.4f}")
    print(f"  Top 20% min:   {min(top_20_values):.4f} â† ì¼ë°˜í™” ìµœì†Œê°’")
    print(f"  Recommendation for Medium: [{min(top_20_values):.4f}, {max(top_20_values):.4f}]")
```

```bash
python analyze_quick_results.py
```

### Step 1-3: Medium ì¤€ë¹„ - ë²”ìœ„ ì¶•ì†Œ ê¸°ì¤€

**íŒŒë¼ë¯¸í„° ê³ ì • vs íƒìƒ‰ ê²°ì • ê¸°ì¤€**:

```python
# ê²°ì • íŠ¸ë¦¬
if param_importance > 0.1:
    # ì¤‘ìš” íŒŒë¼ë¯¸í„° â†’ Mediumì—ì„œ ê³„ì† íƒìƒ‰
    # ë‹¨, Quick ê²°ê³¼ë¡œ ë²”ìœ„ ì¶•ì†Œ

    if param == "dropout_rate":
        # ì¼ë°˜í™”ë¥¼ ìœ„í•œ ìµœì†Œê°’ ì„¤ì •
        min_val = top_20_min * 1.1  # ìƒìœ„ 20% ìµœì†Œê°’ì˜ 110%
        max_val = top_20_max

    elif param == "lr":
        # Log scale íŒŒë¼ë¯¸í„°
        min_val = top_20_min * 0.5
        max_val = top_20_max * 1.5

    else:
        # ì¼ë°˜ íŒŒë¼ë¯¸í„°
        min_val = top_20_min * 0.9
        max_val = top_20_max * 1.1

elif param_importance < 0.05:
    # ëœ ì¤‘ìš” íŒŒë¼ë¯¸í„° â†’ ê³ ì •
    fixed_val = best_trial_value

else:
    # ì¤‘ê°„ ì¤‘ìš”ë„ â†’ ì¢ì€ ë²”ìœ„ íƒìƒ‰
    min_val = top_20_min * 0.95
    max_val = top_20_max * 1.05
```

**ì˜ˆì‹œ**:

```python
# Quick ê²°ê³¼ (ê°€ì •)
Importance:
  lr: 0.35              # ë§¤ìš° ì¤‘ìš”
  dropout_rate: 0.25    # ì¤‘ìš”
  weight_decay: 0.18    # ì¤‘ìš”
  batch_size: 0.12      # ì¤‘ê°„
  num_heads: 0.06       # ëœ ì¤‘ìš”
  hidden_units: 0.04    # ëœ ì¤‘ìš”

Top 20% ë²”ìœ„:
  lr: [0.0015, 0.0030]
  dropout_rate: [0.15, 0.25]  # ìµœì†Œê°’ 0.15 â† ì¼ë°˜í™” ì¤‘ìš”!
  weight_decay: [0.02, 0.08]  # ìµœì†Œê°’ 0.02 â† ì¼ë°˜í™” ì¤‘ìš”!

# Medium search space
lr = trial.suggest_float("lr", 0.001, 0.004, log=True)  # Ã—0.67, Ã—1.33
dropout_rate = trial.suggest_float("dropout_rate", 0.165, 0.25)  # ìµœì†Œê°’ 110%
weight_decay = trial.suggest_float("weight_decay", 0.022, 0.08)  # ìµœì†Œê°’ 110%
batch_size = trial.suggest_categorical("batch_size", [128, 256])  # ì¶•ì†Œ
num_heads = 8  # ê³ ì • (best value)
hidden_units = 256  # ê³ ì • (best value)
```

---

## Stage 2: Medium Mode - ì •ë°€ íƒìƒ‰

**ëª©ì **:
- Quickì—ì„œ ì°¾ì€ promising ì˜ì—­ì„ ì •ë°€ íƒìƒ‰
- ì¶©ë¶„í•œ epochs (50)ë¡œ ì•ˆì •ì ì¸ ì„±ëŠ¥ í™•ì¸
- ì¼ë°˜í™” íŒŒë¼ë¯¸í„° ìµœì†Œê°’ ë³´ì¥

### Step 2-1: Medium Search Space ì„¤ì •

```python
# tune_bert4rec_optuna.py ìˆ˜ì •
# Medium mode ì„¤ì •

class OptunaObjective:
    def __call__(self, trial: optuna.Trial):
        # Seed ê³ ì •
        import lightning as L
        L.seed_everything(42, workers=True)

        # ===== Fixed Parameters (Quick ê²°ê³¼ë¡œ ê³ ì •) =====
        hidden_units = 256  # Quick best
        num_heads = 8       # Quick best
        num_layers = 3      # Quick best
        max_len = 200       # Quick best

        # ===== High Priority (ë„“ê²Œ íƒìƒ‰) =====
        lr = trial.suggest_float("lr", 0.001, 0.004, log=True)

        # ===== Regularization (ì¼ë°˜í™” ìµœì†Œê°’ ë³´ì¥) =====
        dropout_rate = trial.suggest_float("dropout_rate", 0.165, 0.28)
        # ìµœì†Œê°’ 0.165 = Quick top 20% min (0.15) Ã— 1.1
        # â†’ ì¼ë°˜í™” ë³´ì¥

        weight_decay = trial.suggest_float("weight_decay", 0.022, 0.09)
        # ìµœì†Œê°’ 0.022 = Quick top 20% min (0.02) Ã— 1.1
        # â†’ L2 regularization ë³´ì¥

        random_mask_prob = trial.suggest_float("random_mask_prob", 0.17, 0.23)
        # Data augmentation ì¶©ë¶„íˆ

        # ===== Medium Priority (ì¢ê²Œ íƒìƒ‰) =====
        batch_size = trial.suggest_categorical("batch_size", [128, 256])
        last_item_mask_ratio = trial.suggest_float("last_item_mask_ratio", 0.05, 0.12)

        # ... rest of training ...
```

### Step 2-2: Medium Tuning ì‹¤í–‰

**quick_tune.py ì‚¬ìš© (ê¶Œì¥)**:
```bash
cd ~/juik/lightning/tune

# Medium mode ì‹¤í–‰ (50 trials, 50 epochs)
python quick_tune.py --mode medium
```

**ë˜ëŠ” ì§ì ‘ ì‹¤í–‰**:
```bash
python tune_bert4rec_optuna.py \
    --study_name bert4rec_medium \
    --n_trials 50 \
    --n_epochs 50 \
    --n_jobs 1
```

**ì˜ˆìƒ ì‹œê°„**: ì•½ 8-12ì‹œê°„ (50 trials Ã— 50 epochs, pruningìœ¼ë¡œ ì¡°ê¸° ì¢…ë£Œ)

**ëª¨ë‹ˆí„°ë§**:
```bash
# ë‹¤ë¥¸ í„°ë¯¸ë„ì—ì„œ
optuna-dashboard sqlite:///bert4rec_medium.db --port 8080
# ë¸Œë¼ìš°ì €: http://localhost:8080
```

### Step 2-3: Medium ê²°ê³¼ ë¶„ì„

```python
# analyze_medium_results.py
import optuna
import numpy as np

study = optuna.load_study(
    study_name="bert4rec_medium",
    storage="sqlite:///bert4rec_medium.db"
)

completed = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]
best_trial = study.best_trial

print("=" * 80)
print("Medium Tuning Results")
print("=" * 80)

print(f"\nBest Trial: #{best_trial.number}")
print(f"Best NDCG@10: {best_trial.value:.6f}")

print("\nBest Hyperparameters:")
for key, value in sorted(best_trial.params.items()):
    print(f"  {key:25s}: {value}")

# Overfitting ì²´í¬
print("\n" + "=" * 80)
print("Overfitting Check")
print("=" * 80)

# Top 10 trialsì˜ regularization íŒŒë¼ë¯¸í„°
top_trials = sorted(completed, key=lambda t: t.value, reverse=True)[:10]

reg_params = ['dropout_rate', 'weight_decay', 'random_mask_prob']
for param in reg_params:
    values = [t.params[param] for t in top_trials if param in t.params]
    print(f"\n{param} (Top 10 trials):")
    print(f"  Min: {min(values):.4f}")
    print(f"  Max: {max(values):.4f}")
    print(f"  Avg: {np.mean(values):.4f}")

    # ê²½ê³ 
    if param == "dropout_rate" and min(values) < 0.15:
        print("  âš ï¸ Warning: Too low dropout may cause overfitting")
    if param == "weight_decay" and min(values) < 0.01:
        print("  âš ï¸ Warning: Too low weight_decay may cause overfitting")

# Best config ì €ì¥
print("\n" + "=" * 80)
print("Saving Best Config")
print("=" * 80)

best_config = {
    "model": {
        "hidden_units": 256,  # Fixed
        "num_heads": 8,       # Fixed
        "num_layers": 3,      # Fixed
        "max_len": 200,       # Fixed
        "dropout_rate": best_trial.params["dropout_rate"],
        "random_mask_prob": best_trial.params["random_mask_prob"],
        "last_item_mask_ratio": best_trial.params["last_item_mask_ratio"],
    },
    "training": {
        "lr": best_trial.params["lr"],
        "weight_decay": best_trial.params["weight_decay"],
    },
    "data": {
        "batch_size": best_trial.params["batch_size"],
    },
    "best_score": best_trial.value,
}

import yaml
with open("results/bert4rec_medium_best_config.yaml", "w") as f:
    yaml.dump(best_config, f)

print("âœ“ Saved to results/bert4rec_medium_best_config.yaml")
```

```bash
python analyze_medium_results.py
```

---

## Stage 3: Seed Search - ì¬í˜„ì„± í™•ë³´

**ëª©ì **:
- Medium best configì— ìµœì í™”ëœ seed ì°¾ê¸°
- ì¬í˜„ ê°€ëŠ¥í•œ ìµœì¢… ëª¨ë¸

**ì£¼ì˜**: Seed íƒìƒ‰ì€ ë³´í†µ **ë¶ˆí•„ìš”**í•˜ê±°ë‚˜ **ë¹„íš¨ìœ¨ì **
- ì´ìœ : Seed ê³µê°„ì´ ë„ˆë¬´ í¼ (43ì–µ)
- ëŒ€ì•ˆ: Seed=42 ê³ ì • + ì „ì²´ ì¬íŠœë‹

### Option A: Seed ê³ ì • (ê¶Œì¥)

```python
# Medium ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
# Seed=42ë¡œ ê³ ì •ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì™„ì „ ì¬í˜„ ê°€ëŠ¥

# bert4rec_v2.yamlì— Medium best config ì ìš©
# ì¬í•™ìŠµ
./run_bert4rec.sh train bert4rec_v2
```

### Option B: Seed ë²”ìœ„ ì œí•œ íƒìƒ‰ (ì„ íƒì‚¬í•­)

**ì–¸ì œ ì‚¬ìš©?**
- Medium bestê°€ ì•½ê°„ ë¶ˆì•ˆì •í•  ë•Œ
- ì—¬ëŸ¬ seedë¡œ ì•™ìƒë¸”í•˜ê³  ì‹¶ì„ ë•Œ

```python
# tune_seed_only.py
"""
Seed-only tuning with fixed hyperparameters
WARNING: ë³´í†µ ë¹„íš¨ìœ¨ì , ì‹ ì¤‘íˆ ì‚¬ìš©
"""

class SeedOnlyObjective:
    def __init__(self, fixed_params):
        self.fixed_params = fixed_params

    def __call__(self, trial: optuna.Trial):
        # Seedë§Œ íƒìƒ‰ (0-999 ë²”ìœ„)
        seed = trial.suggest_int("seed", 0, 999)

        import lightning as L
        L.seed_everything(seed, workers=True)

        # Fixed params ì‚¬ìš©
        datamodule = BERT4RecDataModule(
            batch_size=self.fixed_params["batch_size"],
            seed=seed,  # DataModule seedë„ ë§ì¶¤
            ...
        )

        model = BERT4Rec(
            dropout_rate=self.fixed_params["dropout_rate"],
            lr=self.fixed_params["lr"],
            ...
        )

        trainer = L.Trainer(max_epochs=60, ...)
        trainer.fit(model, datamodule)

        return trainer.callback_metrics["val_ndcg@10"].item()

# Medium best params ë¡œë“œ
with open("results/bert4rec_medium_best_config.yaml") as f:
    medium_best = yaml.safe_load(f)

fixed_params = {
    **medium_best["model"],
    **medium_best["training"],
    **medium_best["data"],
}

# Seed íƒìƒ‰ (10-20 trials)
study = optuna.create_study(
    study_name="bert4rec_seed_search",
    direction="maximize",
    storage="sqlite:///bert4rec_seed.db"
)

objective = SeedOnlyObjective(fixed_params)
study.optimize(objective, n_trials=15)

print(f"Best seed: {study.best_trial.params['seed']}")
print(f"Best NDCG@10: {study.best_trial.value:.4f}")
```

```bash
# ì‹¤í–‰ (ì„ íƒì‚¬í•­)
python tune_seed_only.py
```

**ì˜ˆìƒ ì‹œê°„**: 5-7ì‹œê°„ (15 trials Ã— 30ë¶„)

---

## 4. ì¼ë°˜í™”ë¥¼ ìœ„í•œ ì „ëµ

### 4.1 Regularization íŒŒë¼ë¯¸í„° ìµœì†Œê°’ ë³´ì¥

**ì›ì¹™**: Overfitting ë°©ì§€ > Val score ìµœëŒ€í™”

```python
# âŒ ë‚˜ìœ ì˜ˆ: ë²”ìœ„ì— 0 í¬í•¨
dropout_rate = trial.suggest_float("dropout_rate", 0.0, 0.3)
weight_decay = trial.suggest_float("weight_decay", 0.0, 0.1)

# âœ… ì¢‹ì€ ì˜ˆ: ì ì ˆí•œ ìµœì†Œê°’
dropout_rate = trial.suggest_float("dropout_rate", 0.15, 0.3)   # â‰¥ 0.15
weight_decay = trial.suggest_float("weight_decay", 0.01, 0.1)   # â‰¥ 0.01
random_mask_prob = trial.suggest_float("random_mask_prob", 0.15, 0.25)  # â‰¥ 0.15
```

### 4.2 Train/Val Gap Monitoring

```python
# Objectiveì— gap penalty ì¶”ê°€ (ì„ íƒì‚¬í•­)

def __call__(self, trial):
    trainer.fit(model, datamodule)

    val_ndcg = trainer.callback_metrics["val_ndcg@10"].item()

    # Train scoreë„ ê¸°ë¡í–ˆë‹¤ë©´
    train_ndcg = trainer.callback_metrics.get("train_ndcg@10", val_ndcg)

    # Gap penalty
    gap = max(0, train_ndcg - val_ndcg)
    if gap > 0.02:  # Gap ë„ˆë¬´ í¬ë©´ penalty
        penalty = gap * 0.5
    else:
        penalty = 0

    objective_value = val_ndcg - penalty

    return objective_value
```

### 4.3 Conservative Approach

```python
# Best trial ëŒ€ì‹  Top-K í‰ê·  ì‚¬ìš© (ë” robust)

completed = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]
top_k = sorted(completed, key=lambda t: t.value, reverse=True)[:5]

# ê° íŒŒë¼ë¯¸í„°ì˜ Top-K í‰ê· 
avg_params = {}
for param in top_k[0].params.keys():
    values = [t.params[param] for t in top_k]
    if isinstance(values[0], (int, float)):
        avg_params[param] = np.mean(values)
    else:
        # Categorical: ìµœë¹ˆê°’
        from collections import Counter
        avg_params[param] = Counter(values).most_common(1)[0][0]

print("Top-5 Average Params (more robust):")
print(avg_params)
```

### 4.4 Ensemble Strategy

```python
# Top-K modelsë¡œ ensemble
top_k_trials = sorted(completed, key=lambda t: t.value, reverse=True)[:5]

models = []
for trial in top_k_trials:
    model = train_with_config(trial.params)
    models.append(model)

# Prediction
def ensemble_predict(models, dataloader):
    all_scores = []
    for model in models:
        scores = model.predict(dataloader)
        all_scores.append(scores)

    # Average
    ensemble_scores = torch.stack(all_scores).mean(dim=0)
    return ensemble_scores
```

---

## 5. Tuning vs Training í™˜ê²½ ì¼ì¹˜

### 5.1 ì²´í¬ë¦¬ìŠ¤íŠ¸

| í•­ëª© | Tuning | Training | ì¼ì¹˜ ì—¬ë¶€ |
|------|--------|----------|-----------|
| Seed | `L.seed_everything(42)` | `L.seed_everything(cfg.data.seed)` | âœ… |
| LR Scheduler | ì—†ìŒ | ì—†ìŒ | âœ… |
| Dataset Split | `seq[:-1]` / `seq[-1]` | `seq[:-1]` / `seq[-1]` | âœ… |
| Loss Function | `CrossEntropy` | `CrossEntropy` | âœ… |
| Validation Metric | `NDCG@10` | `NDCG@10` | âœ… |
| Early Stopping | `patience=5` | `patience=10` | âš ï¸ |
| Precision | `16-mixed` | `16-mixed` | âœ… |
| Gradient Clip | `5.0` | `5.0` | âœ… |

### 5.2 ë¶ˆì¼ì¹˜ ë°œê²¬ ì‹œ ëŒ€ì²˜

**Scheduler ë¶ˆì¼ì¹˜**:
```python
# src/models/bert4rec.py
def configure_optimizers(self):
    optimizer = torch.optim.AdamW(...)
    # scheduler = ...  # ì£¼ì„ì²˜ë¦¬
    return optimizer
```

**Early Stopping ë¶ˆì¼ì¹˜**:
```python
# Tuning patienceë¥¼ Trainingê³¼ ë§ì¶¤
EarlyStopping(patience=10, ...)  # Trainingê³¼ ë™ì¼
```

---

## 6. íŒŒë¼ë¯¸í„°ë³„ ê°€ì´ë“œ

### 6.1 Model Architecture

| Parameter | Quick Range | Medium Range | Fixed | ì„¤ëª… |
|-----------|-------------|--------------|-------|------|
| `hidden_units` | [128, 256] | 256 | âœ“ | Embedding ì°¨ì› |
| `num_heads` | [2, 4, 8] | 8 | âœ“ | Attention heads |
| `num_layers` | [2, 3] | 3 | âœ“ | Transformer layers |
| `max_len` | [100, 150, 200] | 200 | âœ“ | Sequence ê¸¸ì´ |

**ê³ ì • ê¸°ì¤€**: Importance < 0.05 ë˜ëŠ” Best trialì—ì„œ ëª…í™•í•œ ì„ í˜¸

### 6.2 Regularization (ì¼ë°˜í™” í•µì‹¬!)

| Parameter | Quick Range | Medium Range | ìµœì†Œê°’ | ì„¤ëª… |
|-----------|-------------|--------------|--------|------|
| `dropout_rate` | [0.1, 0.3] | [0.15, 0.28] | **0.15** | Dropout (ë†’ì„ìˆ˜ë¡ regularization) |
| `weight_decay` | [0.0, 0.1] | [0.02, 0.09] | **0.02** | L2 reg (0ì´ë©´ regularization ì—†ìŒ) |
| `random_mask_prob` | [0.15, 0.25] | [0.17, 0.23] | **0.15** | Data augmentation |
| `last_item_mask_ratio` | [0.0, 0.2] | [0.05, 0.12] | 0.0 | ì¶”ê°€ masking |

**ì¤‘ìš”**: ìµœì†Œê°’ì„ ì¶©ë¶„íˆ í¬ê²Œ ì„¤ì •í•´ì•¼ overfitting ë°©ì§€

### 6.3 Training

| Parameter | Quick Range | Medium Range | Log Scale | ì„¤ëª… |
|-----------|-------------|--------------|-----------|------|
| `lr` | [8e-4, 5e-3] | [1e-3, 4e-3] | âœ“ | Learning rate |
| `weight_decay` | ìœ„ ì°¸ì¡° | ìœ„ ì°¸ì¡° | | L2 regularization |
| `batch_size` | [128, 256, 512] | [128, 256] | | Batch size |

### 6.4 Data

| Parameter | Quick Range | Medium Range | ì„¤ëª… |
|-----------|-------------|--------------|------|
| `batch_size` | [128, 256, 512] | [128, 256] | ì‘ì„ìˆ˜ë¡ regularization |
| `random_mask_prob` | ìœ„ ì°¸ì¡° | ìœ„ ì°¸ì¡° | Masking í™•ë¥  |
| `last_item_mask_ratio` | ìœ„ ì°¸ì¡° | ìœ„ ì°¸ì¡° | Last item masking |

---

## 7. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 7.1 ValueError: CategoricalDistribution does not support dynamic value space

**ì›ì¸**: ê¸°ì¡´ studyì˜ search spaceì™€ í˜„ì¬ ì½”ë“œ ë¶ˆì¼ì¹˜

**í•´ê²°**:
```bash
# Option 1: ìƒˆ study ìƒì„±
python tune_bert4rec_optuna.py --study_name new_study --n_trials 50

# Option 2: ê¸°ì¡´ study ì‚­ì œ (ë°±ì—… í›„!)
cp old_study.db old_study_backup.db
rm old_study.db
python tune_bert4rec_optuna.py --study_name old_study --n_trials 50
```

### 7.2 Val NDCG@10 ë†’ì€ë° Public Score ë‚®ìŒ

**ì›ì¸**: Overfitting

**í•´ê²°**:
```yaml
# bert4rec_v2.yaml ìˆ˜ì •
model:
  dropout_rate: 0.25  # ì¦ê°€

training:
  weight_decay: 0.05  # ì¦ê°€ (0.001 â†’ 0.05)

data:
  batch_size: 128     # ê°ì†Œ (256 â†’ 128)
```

### 7.3 Tuning ê²°ê³¼ê°€ Trainingì— ì¬í˜„ ì•ˆë¨

**ì›ì¸**: í™˜ê²½ ë¶ˆì¼ì¹˜ (scheduler, seed ë“±)

**í•´ê²°**: [5. Tuning vs Training í™˜ê²½ ì¼ì¹˜](#5-tuning-vs-training-í™˜ê²½-ì¼ì¹˜) ì²´í¬ë¦¬ìŠ¤íŠ¸ í™•ì¸

### 7.4 Seed íƒìƒ‰ìœ¼ë¡œ 0.1 ë‹¬ì„± ëª»í•¨

**ì›ì¸**: Seed-í•˜ì´í¼íŒŒë¼ë¯¸í„° ìƒí˜¸ì‘ìš©

**í•´ê²°**:
```bash
# Seed ê³ ì • + ì „ì²´ ì¬íŠœë‹
# tune_bert4rec_optuna.pyì— L.seed_everything(42) ì¶”ê°€
python tune_bert4rec_optuna.py --study_name bert4rec_seed42 --n_trials 50
```

---

## 8. Best Practices

### 8.1 Tuning Checklist

- [ ] **í™˜ê²½ ê²€ì¦ ì™„ë£Œ** (Stage 0)
- [ ] **Tuning = Training í™˜ê²½** (Scheduler, Seed, Dataset split ì¼ì¹˜)
- [ ] **Regularization ìµœì†Œê°’ ì„¤ì •** (dropout â‰¥ 0.15, weight_decay â‰¥ 0.02)
- [ ] **Quick â†’ Medium ë‹¨ê³„ì  íƒìƒ‰**
- [ ] **ëª¨ë“  ê²°ê³¼ ì €ì¥ ë° ë°±ì—…**
- [ ] **Overfitting ì²´í¬** (Train/Val gap < 0.02)
- [ ] **ìµœì¢… config ê²€ì¦** (Trainingìœ¼ë¡œ ì¬í˜„ í™•ì¸)

### 8.2 ì‹œê°„ ì˜ˆì‚°ë³„ ì „ëµ

**1ì¼ (24ì‹œê°„)**:
- Quick (15 trials Ã— 30 epochs) â†’ 5ì‹œê°„
- Medium (30 trials Ã— 50 epochs) â†’ 15ì‹œê°„
- ë¶„ì„ ë° ìµœì¢… training â†’ 4ì‹œê°„

**2-3ì¼ (48-72ì‹œê°„)**:
- Quick (20 trials Ã— 30 epochs) â†’ 7ì‹œê°„
- Medium (50 trials Ã— 50 epochs) â†’ 25ì‹œê°„
- Seed search (15 trials Ã— 60 epochs) â†’ 8ì‹œê°„
- ì•™ìƒë¸” ì¤€ë¹„ â†’ 10ì‹œê°„

**1ì£¼ì¼+**:
- Quick (30 trials) â†’ 10ì‹œê°„
- Medium (100 trials) â†’ 50ì‹œê°„
- Multiple seed ensembles â†’ 30ì‹œê°„
- Validation ì „ëµ ì‹¤í—˜ â†’ 20ì‹œê°„

### 8.3 ë¦¬ì†ŒìŠ¤ ìµœì í™”

**GPU 1ê°œ**:
```bash
python tune_bert4rec_optuna.py --n_jobs 1
```

**GPU 2ê°œ+**:
```bash
# ì£¼ì˜: Multi-GPUëŠ” ì„±ëŠ¥ í–¥ìƒ ë¯¸ë¯¸, 1ê°œì”© ë…ë¦½ ì‹¤í–‰ ê¶Œì¥
CUDA_VISIBLE_DEVICES=0 python tune_bert4rec_optuna.py --study_name study_1 &
CUDA_VISIBLE_DEVICES=1 python tune_bert4rec_optuna.py --study_name study_2 &
```

**ëª¨ë‹ˆí„°ë§**:
```bash
# Terminal 1: Training
python tune_bert4rec_optuna.py ...

# Terminal 2: Dashboard
optuna-dashboard sqlite:///bert4rec_medium.db --port 8080

# Terminal 3: GPU ëª¨ë‹ˆí„°ë§
watch -n 1 nvidia-smi
```

### 8.4 ìµœì¢… Training ì „ ê²€ì¦

```python
# final_validation.py
"""
Best configë¡œ 5ë²ˆ í•™ìŠµí•˜ì—¬ ì¬í˜„ì„± ë° ì•ˆì •ì„± í™•ì¸
"""

import yaml
from train_with_config import train

with open("results/bert4rec_medium_best_config.yaml") as f:
    best_config = yaml.safe_load(f)

results = []
for run in range(5):
    print(f"\n{'='*80}")
    print(f"Validation Run {run+1}/5")
    print(f"{'='*80}")

    # Seed ê³ ì • (ì¬í˜„ì„±)
    best_config["data"]["seed"] = 42

    result = train(best_config)
    results.append(result["val_ndcg@10"])

    print(f"Val NDCG@10: {result['val_ndcg@10']:.4f}")

print(f"\n{'='*80}")
print("Validation Results")
print(f"{'='*80}")
print(f"Mean: {np.mean(results):.4f}")
print(f"Std:  {np.std(results):.4f}")
print(f"Min:  {min(results):.4f}")
print(f"Max:  {max(results):.4f}")

if np.std(results) < 0.002:
    print("\nâœ“ Stable and reproducible!")
else:
    print("\nâš  High variance, check seed configuration")
```

---

## 9. Quick Reference

### 9.1 ëª…ë ¹ì–´ ëª¨ìŒ

```bash
# Stage 0: Test
python tune_bert4rec_optuna.py --study_name test --n_trials 1 --n_epochs 3

# Stage 1: Quick
python quick_tune.py

# Stage 2: Medium
python tune_bert4rec_optuna.py --study_name bert4rec_medium --n_trials 50 --n_epochs 50

# Stage 3: Seed (ì„ íƒ)
python tune_seed_only.py

# ê²°ê³¼ ë¶„ì„
python analyze_quick_results.py
python analyze_medium_results.py

# ìµœì¢… Training
./run_bert4rec.sh train bert4rec_v2

# Dashboard
optuna-dashboard sqlite:///bert4rec_medium.db --port 8080
```

### 9.2 íŒŒì¼ ê²½ë¡œ

```
tune/
â”œâ”€â”€ tune_bert4rec_optuna.py       # Main tuning script
â”œâ”€â”€ quick_tune.py                  # Quick mode
â”œâ”€â”€ analyze_quick_results.py       # Quick ë¶„ì„
â”œâ”€â”€ analyze_medium_results.py      # Medium ë¶„ì„
â”œâ”€â”€ tune_seed_only.py             # Seed search
â”œâ”€â”€ verify_env.py                 # í™˜ê²½ ê²€ì¦
â””â”€â”€ results/
    â”œâ”€â”€ bert4rec_quick_best_config.yaml
    â”œâ”€â”€ bert4rec_medium_best_config.yaml
    â””â”€â”€ ...

*.db                              # Optuna study databases
```

---

## ë¶€ë¡ A: íŒŒë¼ë¯¸í„° ì¤‘ìš”ë„ í•´ì„

| Importance | ì˜ë¯¸ | ì¡°ì¹˜ |
|------------|------|------|
| > 0.3 | ë§¤ìš° ì¤‘ìš” | Mediumì—ì„œ ë„“ê²Œ íƒìƒ‰ |
| 0.1 ~ 0.3 | ì¤‘ìš” | Mediumì—ì„œ ì¢ê²Œ íƒìƒ‰ |
| 0.05 ~ 0.1 | ì¤‘ê°„ | Mediumì—ì„œ ì¢ê²Œ ë˜ëŠ” ê³ ì • |
| < 0.05 | ëœ ì¤‘ìš” | ê³ ì • (Best value) |

## ë¶€ë¡ B: Regularization ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] `dropout_rate â‰¥ 0.15`
- [ ] `weight_decay â‰¥ 0.01`
- [ ] `random_mask_prob â‰¥ 0.15`
- [ ] `batch_size â‰¤ 256` (ì‘ì„ìˆ˜ë¡ regularization)
- [ ] Train/Val gap < 0.02
- [ ] Early stopping patience = 10 (ì¶©ë¶„í•œ í•™ìŠµ)

## ë¶€ë¡ C: ì¼ë°˜í™” vs Overfitting ì‹ í˜¸

**ì¢‹ì€ ì‹ í˜¸ (ì¼ë°˜í™”)**:
- Val NDCG@10 = 0.095, Public = 0.100 âœ“
- Dropout â‰¥ 0.2, Weight decay â‰¥ 0.03
- Train/Val gap < 0.02

**ë‚˜ìœ ì‹ í˜¸ (Overfitting)**:
- Val NDCG@10 = 0.105, Public = 0.090 âœ—
- Dropout < 0.15, Weight decay < 0.01
- Train/Val gap > 0.03

---

**Last Updated**: 2026-01-02
**Version**: 2.0
